{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aprendizaje por Refuerzo: el Pong"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El artículo completo en el blog [Aprende Machine Learning](http://www.aprendemachinelearning.com) en Español.\n",
    "\n",
    "Crearemos el juego del pong con interface gráfica de Matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El Agente deberá aprender a jugar sólo mediante premios y castigos.\n",
    "\n",
    "Crearemos las clases:\n",
    "\n",
    "* Agente: implementará el algoritmo de QLearning\n",
    "* Environment: será nuestro tablero de juego\n",
    "\n",
    "Y crearemos una función para comenzar a jugar, donde entrenará iterando miles de partidas de pong.\n",
    "\n",
    "Finalmente, ejecutarmos 1 partida con el agente ya entrenado\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-27T10:21:01.578976Z",
     "start_time": "2020-12-27T10:20:58.063893Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from random import randint\n",
    "from time import sleep\n",
    "from IPython.display import clear_output\n",
    "from math import ceil,floor\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clase Agente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-27T10:22:24.177788Z",
     "start_time": "2020-12-27T10:22:24.158177Z"
    }
   },
   "outputs": [],
   "source": [
    "class PongAgent:\n",
    "    \n",
    "    def __init__(self, game, policy=None, discount_factor = 0.1, learning_rate = 0.1, ratio_explotacion = 0.9):\n",
    "\n",
    "        # Creamos la tabla de politicas\n",
    "        if policy is not None:\n",
    "            self._q_table = policy\n",
    "        else:\n",
    "            position = list(game.positions_space.shape)\n",
    "            position.append(len(game.action_space))\n",
    "            self._q_table = np.zeros(position)\n",
    "        \n",
    "        self.discount_factor = discount_factor\n",
    "        self.learning_rate = learning_rate\n",
    "        self.ratio_explotacion = ratio_explotacion\n",
    "\n",
    "    def get_next_step(self, state, game):\n",
    "        \n",
    "        # Damos un paso aleatorio...\n",
    "        next_step = np.random.choice(list(game.action_space))\n",
    "        \n",
    "        # o tomaremos el mejor paso...\n",
    "        if np.random.uniform() <= self.ratio_explotacion:\n",
    "            # tomar el maximo\n",
    "            idx_action = np.random.choice(np.flatnonzero(\n",
    "                    self._q_table[state[0],state[1],state[2]] == self._q_table[state[0],state[1],state[2]].max()\n",
    "                ))\n",
    "            next_step = list(game.action_space)[idx_action]\n",
    "\n",
    "        return next_step\n",
    "\n",
    "    # actualizamos las politicas con las recompensas obtenidas\n",
    "    def update(self, game, old_state, action_taken, reward_action_taken, new_state, reached_end):\n",
    "        idx_action_taken =list(game.action_space).index(action_taken)\n",
    "\n",
    "        actual_q_value_options = self._q_table[old_state[0], old_state[1], old_state[2]]\n",
    "        actual_q_value = actual_q_value_options[idx_action_taken]\n",
    "\n",
    "        future_q_value_options = self._q_table[new_state[0], new_state[1], new_state[2]]\n",
    "        future_max_q_value = reward_action_taken  +  self.discount_factor*future_q_value_options.max()\n",
    "        if reached_end:\n",
    "            future_max_q_value = reward_action_taken #maximum reward\n",
    "\n",
    "        self._q_table[old_state[0], old_state[1], old_state[2], idx_action_taken] = actual_q_value + \\\n",
    "                                              self.learning_rate*(future_max_q_value -actual_q_value)\n",
    "    \n",
    "    def print_policy(self):\n",
    "        for row in np.round(self._q_table,1):\n",
    "            for column in row:\n",
    "                print('[', end='')\n",
    "                for value in column:\n",
    "                    print(str(value).zfill(5), end=' ')\n",
    "                print('] ', end='')\n",
    "            print('')\n",
    "            \n",
    "    def get_policy(self):\n",
    "        return self._q_table\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clase Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-27T10:22:39.529477Z",
     "start_time": "2020-12-27T10:22:39.493343Z"
    }
   },
   "outputs": [],
   "source": [
    "class PongEnvironment:\n",
    "    \n",
    "    def __init__(self, max_life=3, height_px = 40, width_px = 50, movimiento_px = 3):\n",
    "        \n",
    "        self.action_space = ['Arriba','Abajo']\n",
    "        \n",
    "        self._step_penalization = 0\n",
    "        \n",
    "        self.state = [0,0,0]\n",
    "        \n",
    "        self.total_reward = 0\n",
    "        \n",
    "        self.dx = movimiento_px\n",
    "        self.dy = movimiento_px\n",
    "        \n",
    "        filas = ceil(height_px/movimiento_px)\n",
    "        columnas = ceil(width_px/movimiento_px)\n",
    "        \n",
    "        self.positions_space = np.array([[[0 for z in range(columnas)] \n",
    "                                                  for y in range(filas)] \n",
    "                                                     for x in range(filas)])\n",
    "\n",
    "        self.lives = max_life\n",
    "        self.max_life=max_life\n",
    "        \n",
    "        self.x = randint(int(width_px/2), width_px) \n",
    "        self.y = randint(0, height_px-10)\n",
    "        \n",
    "        self.player_alto = int(height_px/4)\n",
    "\n",
    "        self.player1 = self.player_alto  # posic. inicial del player\n",
    "        \n",
    "        self.score = 0\n",
    "        \n",
    "        self.width_px = width_px\n",
    "        self.height_px = height_px\n",
    "        self.radio = 2.5\n",
    "\n",
    "    def reset(self):\n",
    "        self.total_reward = 0\n",
    "        self.state = [0,0,0]\n",
    "        self.lives = self.max_life\n",
    "        self.score = 0\n",
    "        self.x = randint(int(self.width_px/2), self.width_px) \n",
    "        self.y = randint(0, self.height_px-10)\n",
    "        return self.state\n",
    "\n",
    "    def step(self, action, animate=False):\n",
    "        self._apply_action(action, animate)\n",
    "        done = self.lives <=0 # final\n",
    "        reward = self.score\n",
    "        reward += self._step_penalization\n",
    "        self.total_reward += reward\n",
    "        return self.state, reward , done\n",
    "\n",
    "    def _apply_action(self, action, animate=False):\n",
    "        \n",
    "        if action == \"Arriba\":\n",
    "            self.player1 += abs(self.dy)\n",
    "        elif action == \"Abajo\":\n",
    "            self.player1 -= abs(self.dy)\n",
    "            \n",
    "        self.avanza_player()\n",
    "\n",
    "        self.avanza_frame()\n",
    "\n",
    "        if animate:\n",
    "            clear_output(wait=True);\n",
    "            fig = self.dibujar_frame()\n",
    "            plt.show()\n",
    "\n",
    "        self.state = (floor(self.player1/abs(self.dy))-2, floor(self.y/abs(self.dy))-2, floor(self.x/abs(self.dx))-2)\n",
    "    \n",
    "    def detectaColision(self, ball_y, player_y):\n",
    "        if (player_y+self.player_alto >= (ball_y-self.radio)) and (player_y <= (ball_y+self.radio)):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    def avanza_player(self):\n",
    "        if self.player1 + self.player_alto >= self.height_px:\n",
    "            self.player1 = self.height_px - self.player_alto\n",
    "        elif self.player1 <= -abs(self.dy):\n",
    "            self.player1 = -abs(self.dy)\n",
    "\n",
    "    def avanza_frame(self):\n",
    "        self.x += self.dx\n",
    "        self.y += self.dy\n",
    "        if self.x <= 3 or self.x > self.width_px:\n",
    "            self.dx = -self.dx\n",
    "            if self.x <= 3:\n",
    "                ret = self.detectaColision(self.y, self.player1)\n",
    "\n",
    "                if ret:\n",
    "                    self.score = 10\n",
    "                else:\n",
    "                    self.score = -10\n",
    "                    self.lives -= 1\n",
    "                    if self.lives>0:\n",
    "                        self.x = randint(int(self.width_px/2), self.width_px)\n",
    "                        self.y = randint(0, self.height_px-10)\n",
    "                        self.dx = abs(self.dx)\n",
    "                        self.dy = abs(self.dy)\n",
    "        else:\n",
    "            self.score = 0\n",
    "\n",
    "        if self.y < 0 or self.y > self.height_px:\n",
    "            self.dy = -self.dy\n",
    "\n",
    "    def dibujar_frame(self):\n",
    "        fig = plt.figure(figsize=(5, 4))\n",
    "        a1 = plt.gca()\n",
    "        circle = plt.Circle((self.x, self.y), self.radio, fc='slategray', ec=\"black\")\n",
    "        a1.set_ylim(-5, self.height_px+5)\n",
    "        a1.set_xlim(-5, self.width_px+5)\n",
    "\n",
    "        rectangle = plt.Rectangle((-5, self.player1), 5, self.player_alto, fc='gold', ec=\"none\")\n",
    "        a1.add_patch(circle);\n",
    "        a1.add_patch(rectangle)\n",
    "        #a1.set_yticklabels([]);a1.set_xticklabels([]);\n",
    "        plt.text(4, self.height_px, \"SCORE:\"+str(self.total_reward)+\"  LIFE:\"+str(self.lives), fontsize=12)\n",
    "        if self.lives <=0:\n",
    "            plt.text(10, self.height_px-14, \"GAME OVER\", fontsize=16)\n",
    "        elif self.total_reward >= 1000:\n",
    "            plt.text(10, self.height_px-14, \"YOU WIN!\", fontsize=16)\n",
    "        return fig\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Juego"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-27T10:22:51.265359Z",
     "start_time": "2020-12-27T10:22:51.249319Z"
    }
   },
   "outputs": [],
   "source": [
    "def play(rounds=5000, max_life=3, discount_factor = 0.1, learning_rate = 0.1,\n",
    "         ratio_explotacion=0.9,learner=None, game=None, animate=False):\n",
    "\n",
    "    if game is None:\n",
    "        # si usamos movimiento_px = 5 creamos una tabla de politicas de 8x10\n",
    "        # si usamos movimiento_px = 3 la tabla sera de 14x17\n",
    "        game = PongEnvironment(max_life=max_life, movimiento_px = 3)\n",
    "        \n",
    "    if learner is None:\n",
    "        print(\"Begin new Train!\")\n",
    "        learner = PongAgent(game, discount_factor = discount_factor,learning_rate = learning_rate, ratio_explotacion= ratio_explotacion)\n",
    "\n",
    "    max_points= -9999\n",
    "    first_max_reached = 0\n",
    "    total_rw=0\n",
    "    steps=[]\n",
    "\n",
    "    for played_games in range(0, rounds):\n",
    "        state = game.reset()\n",
    "        reward, done = None, None\n",
    "        \n",
    "        itera=0\n",
    "        while (done != True) and (itera < 3000 and game.total_reward<=1000):\n",
    "            old_state = np.array(state)\n",
    "            next_action = learner.get_next_step(state, game)\n",
    "            state, reward, done = game.step(next_action, animate=animate)\n",
    "            if rounds > 1:\n",
    "                learner.update(game, old_state, next_action, reward, state, done)\n",
    "            itera+=1\n",
    "        \n",
    "        steps.append(itera)\n",
    "        \n",
    "        total_rw+=game.total_reward\n",
    "        if game.total_reward > max_points:\n",
    "            max_points=game.total_reward\n",
    "            first_max_reached = played_games\n",
    "        \n",
    "        if played_games %500==0 and played_games >1 and not animate:\n",
    "            print(\"-- Partidas[\", played_games, \"] Avg.Puntos[\", int(total_rw/played_games),\"]  AVG Steps[\", int(np.array(steps).mean()), \"] Max Score[\", max_points,\"]\")\n",
    "                \n",
    "    if played_games>1:\n",
    "        print('Partidas[',played_games,'] Avg.Puntos[',int(total_rw/played_games),'] Max score[', max_points,'] en partida[',first_max_reached,']')\n",
    "        \n",
    "    #learner.print_policy()\n",
    "    \n",
    "    return learner, game\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-27T10:24:06.516334Z",
     "start_time": "2020-12-27T10:22:51.808220Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin new Train!\n",
      "-- Partidas[ 500 ] Avg.Puntos[ 20 ]  AVG Steps[ 240 ] Max Score[ 160 ]\n",
      "-- Partidas[ 1000 ] Avg.Puntos[ 23 ]  AVG Steps[ 249 ] Max Score[ 200 ]\n",
      "-- Partidas[ 1500 ] Avg.Puntos[ 24 ]  AVG Steps[ 252 ] Max Score[ 200 ]\n",
      "-- Partidas[ 2000 ] Avg.Puntos[ 28 ]  AVG Steps[ 266 ] Max Score[ 250 ]\n",
      "-- Partidas[ 2500 ] Avg.Puntos[ 30 ]  AVG Steps[ 274 ] Max Score[ 300 ]\n",
      "-- Partidas[ 3000 ] Avg.Puntos[ 33 ]  AVG Steps[ 282 ] Max Score[ 300 ]\n",
      "-- Partidas[ 3500 ] Avg.Puntos[ 35 ]  AVG Steps[ 291 ] Max Score[ 340 ]\n",
      "-- Partidas[ 4000 ] Avg.Puntos[ 37 ]  AVG Steps[ 298 ] Max Score[ 340 ]\n",
      "-- Partidas[ 4500 ] Avg.Puntos[ 38 ]  AVG Steps[ 301 ] Max Score[ 520 ]\n",
      "Partidas[ 4999 ] Avg.Puntos[ 40 ] Max score[ 520 ] en partida[ 4104 ]\n"
     ]
    }
   ],
   "source": [
    "learner, game = play(rounds=5000, discount_factor = 0.2, learning_rate = 0.1, ratio_explotacion=0.85)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-27T10:35:16.554658Z",
     "start_time": "2020-12-27T10:25:44.533659Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learner2 = PongAgent(game, policy=learner.get_policy())\n",
    "learner2.ratio_explotacion = 1.0  # con esto quitamos las elecciones aleatorias al jugar\n",
    "player = play(rounds=1, learner=learner2, game=game, animate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
